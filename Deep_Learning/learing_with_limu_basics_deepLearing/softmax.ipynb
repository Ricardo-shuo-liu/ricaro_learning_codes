{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba3ce800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911d9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2f1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "mninst_train = torchvision.datasets.FashionMNIST(\n",
    "    root='FashionMINIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=trans\n",
    "    )\n",
    "mninst_text = torchvision.datasets. FashionMNIST(\n",
    "    root=\"FashionMINIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=trans\n",
    ")\n",
    "\n",
    "\n",
    "len(mninst_train),len(mninst_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f40ba343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mninst_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ab7b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter('log')\n",
    "# for index,data_ in enumerate(mninst_train):\n",
    "#     writer.add_image('Minist',data_[0],index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d19acc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7a695eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    dataset=mninst_train,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "# writer = SummaryWriter('dataloader')\n",
    "\n",
    "# for index,data_ in enumerate(train_dataloader):\n",
    "\n",
    "#     writer.add_images('da',data_[0],index)\n",
    "\n",
    "text_dataloader = data.DataLoader(\n",
    "    dataset = mninst_text,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bde01d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0991, 0.5271, 0.1867, 0.1375, 0.0495],\n",
       "         [0.0396, 0.3836, 0.0796, 0.0404, 0.4569]]),\n",
       " tensor([1., 1.]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "num_inputs = 28*28 \n",
    "num_out = 10\n",
    "w = torch.normal(0,0.01,size=(num_inputs,num_out),requires_grad=True)\n",
    "b = torch.zeros(num_out,requires_grad=True)\n",
    "\n",
    "def softmax(X):\n",
    "    exp_x = torch.exp(X)\n",
    "    p = exp_x.sum(1,keepdim=True)\n",
    "    return exp_x / p\n",
    "\n",
    "X = torch.normal(0,1,(2,5))\n",
    "\n",
    "x_prad = softmax(X)\n",
    "x_prad , x_prad.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5884df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def net(w,b,X):\n",
    "    return softmax(torch.matmul(X.reshape((256,-1)),w) + b )\n",
    "def lossfunction(y_hat , y):\n",
    "\n",
    "    return -torch.log(y_hat[range(y_hat.shape[0]),y])\n",
    "\n",
    "y = torch.tensor([0,2])\n",
    "y_hat = torch.tensor([[0.1,0.3,0.6],\n",
    "                      [0.3,0.2,0.5]])\n",
    "loss = lossfunction(y_hat,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d1cfc669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    predictIndex = y_hat.argmax(axis=1)\n",
    "    result = (predictIndex == y).sum()\n",
    "    return result / y_hat.shape[0]\n",
    "accur = accuracy(y_hat,y)\n",
    "accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e0a76efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr* param.grad/256\n",
    "            \n",
    "            param.grad.zero_()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6b925fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6953)\n",
      "tensor(1.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.7500)\n",
      "tensor(0.8746, grad_fn=<AddBackward0>)\n",
      "tensor(0.7695)\n",
      "tensor(0.7629, grad_fn=<AddBackward0>)\n",
      "tensor(0.7695)\n",
      "tensor(0.7852)\n",
      "tensor(0.7500)\n",
      "tensor(0.7578)\n",
      "tensor(0.7188)\n",
      "tensor(0.7695)\n",
      "tensor(0.7891)\n",
      "tensor(0.7578)\n",
      "tensor(0.7969)\n",
      "tensor(0.7734)\n",
      "tensor(0.7656)\n",
      "tensor(0.7227)\n",
      "tensor(0.6797)\n",
      "tensor(0.7305)\n",
      "tensor(0.7266)\n",
      "tensor(0.6875)\n",
      "tensor(0.7461)\n",
      "tensor(0.8594)\n",
      "tensor(0.7695)\n",
      "tensor(0.7266)\n",
      "tensor(0.7734)\n",
      "tensor(0.7070)\n",
      "tensor(0.7227)\n",
      "tensor(0.7617)\n",
      "tensor(0.7500)\n",
      "tensor(0.7500)\n",
      "tensor(0.7266)\n",
      "tensor(0.7422)\n",
      "tensor(0.7500)\n",
      "tensor(0.7695)\n",
      "tensor(0.7344)\n",
      "tensor(0.7070)\n",
      "tensor(0.7422)\n",
      "tensor(0.7773)\n",
      "tensor(0.7266)\n",
      "tensor(0.7188)\n",
      "tensor(0.7344)\n",
      "tensor(0.7656)\n",
      "tensor(0.7578)\n"
     ]
    }
   ],
   "source": [
    "for _  in range(3):\n",
    "    for X,y in train_dataloader:\n",
    "        y_hat = net(w,b,X)\n",
    "        loss = lossfunction(y_hat,y)\n",
    "        L2 = (0 * w**2).sum()\n",
    "        (loss.sum() + L2).backward()\n",
    "        sgd([w,b],lr=0.01)\n",
    "        ac= accuracy(y_hat,y)\n",
    "    print(ac)\n",
    "    print(loss.sum()/256 + L2)\n",
    "with torch.no_grad():\n",
    "    for X,y in text_dataloader:\n",
    "        y_hat= net(w,b,X)\n",
    "        ac = accuracy(y_hat,y)\n",
    "        print(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a1cdf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6758)\n",
      "tensor(0.9033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7344)\n",
      "tensor(0.8265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7578)\n",
      "tensor(0.8100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7148)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7734)\n",
      "tensor(0.6657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7930)\n",
      "tensor(0.5135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8750)\n",
      "tensor(0.6041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7812)\n",
      "tensor(0.6136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7969)\n",
      "tensor(0.6258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7812)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import(\n",
    "    Sequential,\n",
    "    Flatten,\n",
    "    CrossEntropyLoss,\n",
    "    Linear\n",
    ")\n",
    "from torch.optim import SGD\n",
    "net = Sequential(\n",
    "    Flatten(),\n",
    "    Linear(784,10)\n",
    ")\n",
    "loss_ = CrossEntropyLoss()\n",
    "optimer = SGD(net.parameters(),lr=0.01)\n",
    "for _ in range(10):\n",
    "    for X , y in train_dataloader:\n",
    "        y_hat = net(X)\n",
    "        acc = accuracy(y_hat,y)\n",
    "        loss = loss_(y_hat , y)\n",
    "        optimer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimer.step()\n",
    "    print(loss)\n",
    "    print(acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairseq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
