{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e2e70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "#@save\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def download_all():  #@save\n",
    "    \"\"\"下载DATA_HUB中的所有文件\"\"\"\n",
    "    for name in DATA_HUB:\n",
    "        download(name)\n",
    "# 如果没有安装pandas，请取消下一行的注释\n",
    "# !pip install pandas\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "DATA_HUB['kaggle_house_train'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
    "    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
    "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n",
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74a66636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0683eefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 330)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_featurs = train_data.iloc[:,1:-1]\n",
    "train_labels = train_data.iloc[:,-1:]\n",
    "test_features = test_data.iloc[:,1:]\n",
    "all_featurs = pd.concat((train_featurs,test_features))\n",
    "all_featurs = pd.get_dummies(all_featurs,dummy_na=True)\n",
    "all_featurs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1af76ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_featurs = all_featurs.iloc[:train_data.shape[0],:]\n",
    "test_features = all_featurs.iloc[train_data.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3af7b4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass               0.073350\n",
       "LotFrontage             -0.207948\n",
       "LotArea                 -0.207071\n",
       "OverallQual              0.651256\n",
       "OverallCond             -0.517023\n",
       "                           ...   \n",
       "SaleCondition_Alloca    -0.091003\n",
       "SaleCondition_Family    -0.117811\n",
       "SaleCondition_Normal     0.467491\n",
       "SaleCondition_Partial   -0.305890\n",
       "SaleCondition_nan        0.000000\n",
       "Name: 0, Length: 330, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(x):\n",
    "    y = x.apply(\n",
    "    lambda x: (x - x.mean()) / (x.std())\n",
    "    )\n",
    "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "    y = y.fillna(0)\n",
    "    return y\n",
    "\n",
    "train_featurs = clean_data(train_featurs)\n",
    "test_features = clean_data(test_features)\n",
    "train_featurs.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "360748dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_featurs = torch.tensor(train_featurs.values,dtype=torch.float32)\n",
    "test_features = torch.tensor(test_features.values,dtype=torch.float32)\n",
    "train_labels = train_labels/10000\n",
    "train_labels = torch.tensor(train_labels.values,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2816f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import(\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    "    DataLoader\n",
    ") \n",
    "\n",
    "train_dataset = TensorDataset(train_featurs,train_labels)\n",
    "test_dataset = TensorDataset(test_features)\n",
    "length_train_dataset = len(train_dataset)\n",
    "s1 = int(0.9*length_train_dataset)\n",
    "s2 = length_train_dataset - s1 \n",
    "\n",
    "train_dataset , val_dataset = random_split(train_dataset,[s1,s2])\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b743f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'n_epoch': 1000,\n",
    "    'optimer' : 'Adam',\n",
    "    \"val_limit_loss\" : 20,\n",
    "    \"val_limit_epoch\" : 300,\n",
    "    \"save_path\" : \"../model_house_prices/model.pth\",\n",
    "    'save_predict_path': \"../submission.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7305667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=330, out_features=350, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=350, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import (\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    Module,\n",
    "    Sequential\n",
    ")\n",
    "class MLP(Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mlp = Sequential(\n",
    "            Linear(330,350),\n",
    "            ReLU(),\n",
    "            Linear(350,256),\n",
    "            ReLU(),\n",
    "            Linear(256,128),\n",
    "            ReLU(),\n",
    "            Linear(128,64),\n",
    "            ReLU(),\n",
    "            Linear(64,1)\n",
    "        ) \n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "def init_parter(x):\n",
    "    if isinstance(x,Linear):\n",
    "        torch.nn.init.kaiming_normal_(x.weight,mode='fan_in',nonlinearity='relu')\n",
    "        torch.nn.init.constant_(x.bias,0)\n",
    "\n",
    "mlp = MLP()\n",
    "mlp.apply(init_parter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a07f4245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device(chose_cuda_num = 0):\n",
    "    return f\"cuda:{chose_cuda_num}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "78c3cbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(268.9332, device='cuda:0')\n",
      "tensor(19.1471, device='cuda:0')\n",
      "tensor(14.7980, device='cuda:0')\n",
      "tensor(14.6703, device='cuda:0')\n",
      "tensor(14.7310, device='cuda:0')\n",
      "tensor(15.5085, device='cuda:0')\n",
      "tensor(15.7615, device='cuda:0')\n",
      "tensor(15.7620, device='cuda:0')\n",
      "tensor(16.1086, device='cuda:0')\n",
      "tensor(16.4362, device='cuda:0')\n",
      "tensor(16.5881, device='cuda:0')\n",
      "tensor(16.6142, device='cuda:0')\n",
      "tensor(16.5161, device='cuda:0')\n",
      "tensor(16.5666, device='cuda:0')\n",
      "tensor(16.5194, device='cuda:0')\n",
      "tensor(16.6470, device='cuda:0')\n",
      "tensor(16.6409, device='cuda:0')\n",
      "tensor(16.6664, device='cuda:0')\n",
      "tensor(16.5434, device='cuda:0')\n",
      "tensor(16.6117, device='cuda:0')\n",
      "tensor(16.4152, device='cuda:0')\n",
      "tensor(16.3779, device='cuda:0')\n",
      "tensor(16.7014, device='cuda:0')\n",
      "tensor(16.3274, device='cuda:0')\n",
      "tensor(16.5192, device='cuda:0')\n",
      "tensor(15.9219, device='cuda:0')\n",
      "tensor(16.0815, device='cuda:0')\n",
      "tensor(16.1231, device='cuda:0')\n",
      "tensor(16.1823, device='cuda:0')\n",
      "tensor(16.2856, device='cuda:0')\n",
      "tensor(16.2742, device='cuda:0')\n",
      "tensor(16.7086, device='cuda:0')\n",
      "tensor(15.9973, device='cuda:0')\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "lossfuncton = torch.nn.MSELoss()\n",
    "optimer = getattr(torch.optim,config['optimer'])(mlp.parameters(),lr=0.0001,weight_decay=0.001)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer_val = SummaryWriter(\"../log/val\")\n",
    "writer_train = SummaryWriter(\"../log/train\")\n",
    "\n",
    "def val(model,lossfunction,val_dataloader,device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch = 0\n",
    "        loss = 0\n",
    "        for val_features , val_labels in val_dataloader:\n",
    "            epoch += 1\n",
    "            val_features = val_features.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            y_hat = model(val_features)\n",
    "            loss += lossfunction(y_hat,val_labels).to(device)\n",
    "\n",
    "        return loss/epoch\n",
    "    \n",
    "\n",
    "def train(config,model,lossfunction,optimer,\n",
    "          writer_train,writer_val,train_dataloader,\n",
    "          val_dataloader,device):\n",
    "    n_epoch = config[\"n_epoch\"]\n",
    "    train_epoch = 0\n",
    "    model.train()\n",
    "    val_limit_loss = config[\"val_limit_loss\"]\n",
    "    val_limit_epoch = config[\"val_limit_epoch\"]\n",
    "    limit_epoch = 0 \n",
    "    for epoch in range(n_epoch):\n",
    "        for train_featur,train_label in train_dataloader:\n",
    "            train_epoch += 1\n",
    "            train_featur = train_featur.to(device)\n",
    "            train_label = train_label.to(device)\n",
    "            y_hat = model(train_featur)\n",
    "            loss = lossfunction(y_hat,train_label).to(device)\n",
    "            optimer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimer.step()\n",
    "            writer_train.add_scalar('train',loss,train_epoch)\n",
    "        val_loss =val(model,lossfunction,val_dataloader,device)\n",
    "        if(epoch%10==0):\n",
    "            print(val_loss)\n",
    "        writer_val.add_scalar('val',val_loss,epoch)\n",
    "\n",
    "        if val_loss < val_limit_loss:\n",
    "            val_limit_loss = val_loss\n",
    "            \n",
    "            torch.save(model.state_dict(),config['save_path'])\n",
    "            \n",
    "            limit_epoch = 0\n",
    "        else:\n",
    "            limit_epoch +=1\n",
    "        \n",
    "        if limit_epoch > val_limit_epoch:\n",
    "            break\n",
    "    print(epoch)\n",
    "    writer_train.close()\n",
    "    writer_val.close()\n",
    "mlp = mlp.to(device)\n",
    "train(config=config,\n",
    "      model=mlp,\n",
    "      lossfunction=lossfuncton,\n",
    "      optimer=optimer,\n",
    "      writer_train=writer_train,\n",
    "      writer_val=writer_val,\n",
    "      train_dataloader=train_dataloader,\n",
    "      val_dataloader=val_dataloader,\n",
    "      device=device\n",
    "      )\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e532a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=./log/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ea1e6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_model = MLP().to(device)\n",
    "param_dict = torch.load(config['save_path'])\n",
    "predict_model.load_state_dict(param_dict)\n",
    "\n",
    "def test(model,device,test_dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch = 0\n",
    "        predict = []\n",
    "        for test_features in test_dataloader:\n",
    "            epoch += 1\n",
    "            test_features = test_features[0].to(device)\n",
    "            y_hat = model(test_features)*10000\n",
    "            predict.append(y_hat)\n",
    "    return predict\n",
    "\n",
    "predict_result = test(model=predict_model,\n",
    "     device=device,\n",
    "     test_dataloader=test_dataloader)\n",
    "\n",
    "result = torch.concat(predict_result,dim=0)\n",
    "result.shape\n",
    "\n",
    "def save_reslut(config,result):\n",
    "    save_predict_path = config['save_predict_path']\n",
    "    preds = result.to('cpu').numpy()\n",
    "    ids = range(1461,2920)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Id': ids,\n",
    "        'SalePrice': preds.flatten()  # 确保preds是一维数组\n",
    "    })\n",
    "    df.to_csv(save_predict_path, index=False)\n",
    "save_reslut(config=config,\n",
    "            result=result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairseq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
